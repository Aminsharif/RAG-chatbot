{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f10fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "# Best practice: store your credentials in environment variables\n",
    "weaviate_url = os.environ[\"WEAVIATE_URL\"]\n",
    "weaviate_api_key = os.environ[\"WEAVIATE_API_KEY\"]\n",
    "\n",
    "# Connect to Weaviate Cloud\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=weaviate_url,\n",
    "    auth_credentials=Auth.api_key(weaviate_api_key),\n",
    ")\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72df6f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate_url = os.environ.get(\"WEAVIATE_URL\")\n",
    "weaviate_api_key = os.environ.get(\"WEAVIATE_API_KEY\")\n",
    "import weaviate\n",
    "from weaviate import Client\n",
    "from weaviate.classes.init import Auth\n",
    "from weaviate.classes.query import Filter\n",
    "\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fccee906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\chatbot_project\\RAG-chatbot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "\n",
    "def get_embeddings_model() -> Embeddings:\n",
    "    return HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = WeaviateVectorStore(\n",
    "            client=client,\n",
    "            index_name=\"pdf_index\",\n",
    "            text_key=\"text\",\n",
    "            embedding=get_embeddings_model(),\n",
    "            attributes=[\"source\", \"title\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975655fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = store.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc5df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ret.invoke(\"what is transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242aba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'keywords': '', 'creator': 'LaTeX with hyperref', 'file_path': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf\\\\Attention.pdf', 'trapped': '/False', 'page_label': '3', 'creationdate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'file_name': 'Attention.pdf', 'page': 2.0, 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'directory': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf', 'source': 'C:/Users/amins/AppData/Local/Temp/ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf/Attention.pdf', 'total_pages': 15.0, 'producer': 'pdfTeX-1.40.25', 'moddate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'title': '', 'author': ''}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.'),\n",
       " Document(metadata={'keywords': '', 'creator': 'LaTeX with hyperref', 'file_path': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf\\\\Attention.pdf', 'trapped': '/False', 'page_label': '5', 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'file_name': 'Attention.pdf', 'page': 4.0, 'creationdate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'directory': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf', 'subject': '', 'source': 'C:/Users/amins/AppData/Local/Temp/ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf/Attention.pdf', 'total_pages': 15.0, 'producer': 'pdfTeX-1.40.25', 'moddate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'title': '', 'author': ''}, page_content='The Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward'),\n",
       " Document(metadata={'creator': 'LaTeX with hyperref', 'keywords': '', 'file_path': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf\\\\LLM.pdf', 'trapped': '/False', 'page_label': '5', 'creationdate': datetime.datetime(2024, 4, 11, 0, 8, 1, tzinfo=datetime.timezone.utc), 'file_name': 'LLM.pdf', 'page': 4.0, 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'directory': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf', 'subject': '', 'source': 'C:/Users/amins/AppData/Local/Temp/ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf/LLM.pdf', 'total_pages': 46.0, 'producer': 'pdfTeX-1.40.25', 'moddate': datetime.datetime(2024, 4, 11, 0, 8, 1, tzinfo=datetime.timezone.utc), 'title': 'A Comprehensive Overview of Large Language Models', 'author': 'Humza Naveed; Asad Ullah Khan; Shi Qiu; Muhammad Saqib; Saeed Anwar; Muhammad Usman; Naveed Akhtar; Nick Barnes; Ajmal Mian;'}, page_content='collected through web sources. This data contains private\\ninformation; therefore, many LLMs employ heuristics-based\\nmethods to filter information such as names, addresses, and\\nphone numbers to avoid learning personal information.\\n2.9. Architectures\\nHere we discuss the variants of the transformer architectures\\nused in LLMs. The di fference arises due to the application of\\nFigure 4: An example of attention patterns in language models, image is taken\\nfrom [93].\\nFigure 5: An example of language model training objectives, image from [93].\\nthe attention and the connection of transformer blocks. An il-\\nlustration of attention patterns of these architectures is shown\\nin Figure 4.\\nEncoder Decoder: This architecture processes inputs through\\nthe encoder and passes the intermediate representation to the\\ndecoder to generate the output. Here, the encoder sees the\\ncomplete sequence utilizing self-attention whereas the decoder\\nprocesses the sequence one after the other with implementing'),\n",
       " Document(metadata={'creator': 'LaTeX with hyperref', 'keywords': '', 'file_path': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf\\\\Attention.pdf', 'trapped': '/False', 'page_label': '10', 'creationdate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'file_name': 'Attention.pdf', 'page': 9.0, 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'directory': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf', 'source': 'C:/Users/amins/AppData/Local/Temp/ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf/Attention.pdf', 'total_pages': 15.0, 'producer': 'pdfTeX-1.40.25', 'moddate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'title': '', 'author': ''}, page_content='Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser Training WSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\\nTransformer (4 layers) WSJ only, discriminative 91.3\\nZhu et al. (2013) [40] semi-supervised 91.3\\nHuang & Harper (2009) [14] semi-supervised 91.3\\nMcClosky et al. (2006) [26] semi-supervised 92.1\\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\\nTransformer (4 layers) semi-supervised 92.7\\nLuong et al. (2015) [23] multi-task 93.0\\nDyer et al. (2016) [8] generative 93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0e994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
